{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe52035e",
   "metadata": {},
   "source": [
    "https://github.com/openai/openai-agents-python/blob/main/examples/basic/agent_lifecycle_example.py \n",
    "\n",
    "two agents\n",
    "each has its own tools \n",
    "\n",
    "1. starter agents: will process the initial user request, will use tools as needed and will handoff to other agents if required\n",
    "2. multiply agent: knows how to perform arithmetic operations (can we configure a handoff)\n",
    "\n",
    "example also keeps tracks of agent life cycle events \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0c45d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import (\n",
    "\n",
    "    Agent,\n",
    "    Runner,\n",
    "    RunConfig,\n",
    "    trace,\n",
    "    ModelSettings\n",
    ")\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467e7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "from helpers.trace_util import get_trace_url\n",
    "from agents.extensions.visualization import draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00e1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.model_client import (\n",
    "    get_openai_client,\n",
    "    get_github_model_provider\n",
    ")\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "GITHUB_MODEL_PROVIDER = get_github_model_provider(\n",
    "    client = get_openai_client(),\n",
    "    model = model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1c7ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "from agents import handoff, RunContextWrapper\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str = Field(description=\"The joke text\")\n",
    "    punchline: str = Field(description=\"The punchline of the joke\")\n",
    "    language: str = Field(description=\"The language of the joke\")\n",
    "\n",
    "\n",
    "class Translation(BaseModel):\n",
    "    content: str = Field(description=\"Content\")\n",
    "    language: str = Field(description=\"The language of the translation\")\n",
    "\n",
    "async def on_handoff1(ctx: RunContextWrapper[None], input_data: Translation):\n",
    "    print(f\"agent {ctx} called with: {input_data.content}\")\n",
    "\n",
    "dad_jokes_agent = Agent(\n",
    "    name=\"dad_jokes_generator_agent\",\n",
    "    instructions=(\n",
    "        # f\"{RECOMMENDED_PROMPT_PREFIX} \\n\"\n",
    "        \"You are an agent that specialises in generating jokes, dad jokes specifically. \"\n",
    "        \"You only respond with dad jokes.\"\n",
    "        \"You do not answer any other questions. \"\n",
    "        \"always deliver a punchline. \"\n",
    "        \" ## IMPORTANT ##\"\n",
    "        \"Always respond in English, even if the user asks in a different language. \"\n",
    "        \"You don't end the conversation, you must handoff to another agent.\"\n",
    "    ),\n",
    "    handoff_description=(\n",
    "        \"An agent capable of generating jokes in English\"\n",
    "    ),\n",
    "    model=model_name,\n",
    "    output_type=Joke,\n",
    ")\n",
    "\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"spanish_agent\",\n",
    "    instructions= \"\"\"\n",
    "        You translate the input message to Spanish.\n",
    "        You don't generate new content.\n",
    "        ## IMPORTANT ##\n",
    "        You don't end the conversation, you must handoff to another agent.\n",
    "        only handoff to a single agent at a time\n",
    "\n",
    "        \"\"\",\n",
    "    handoff_description=\"\"\"\n",
    "    You translate content to spanish.\n",
    "    \"\"\",\n",
    "    model=model_name,\n",
    "    output_type=Translation,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "french_agent = Agent(\n",
    "    name=\"french_agent\",\n",
    "    instructions= \"\"\"\n",
    "        You translate the input message to French.\n",
    "        You don't generate new content.\n",
    "        ## IMPORTANT ##\n",
    "        You don't end the conversation, you must handoff to another agent.\n",
    "        only handoff to a single agent at a time\n",
    "\n",
    "\n",
    "        \"\"\",\n",
    "    handoff_description=\"you translate content to french\",\n",
    "    model=model_name,\n",
    "    output_type=Translation,\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968e336f",
   "metadata": {},
   "source": [
    "# Executing a Manual Handoff\n",
    "\n",
    "In this example, we will execute a manual handoff between agents in a sequential workflow. \n",
    "\n",
    "All of the agents produce structured outputs. \n",
    "\n",
    "The output of one agent is used as the input to the next agent, after appending to it an additional handoff instruction message.\n",
    "\n",
    "Notice in the trace afterwards how the full message histtory is preserved, including the handoff instruction message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d568294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def handoff_instructions_msg(lang: str):\n",
    "    return {\"role\": \"user\", \"content\": f\"Translate the following text to {lang}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a8fb4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace URL: https://platform.openai.com/traces/trace?trace_id=trace_995a53902c994ced941e950226be31ff\n",
      "RunResult:\n",
      "- Last agent: Agent(name=\"dad_jokes_generator_agent\", ...)\n",
      "- Final output (Joke):\n",
      "    {\n",
      "      \"joke\": \"Why did the scarecrow win an award?\",\n",
      "      \"punchline\": \"Because he was outstanding in his field!\",\n",
      "      \"language\": \"English\"\n",
      "    }\n",
      "- 1 new item(s)\n",
      "- 1 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n",
      "First joke as Joke: joke='Why did the scarecrow win an award?' punchline='Because he was outstanding in his field!' language='English'\n",
      "Spanish translation as Joke: joke='¿Por qué ganó un premio el espantapájaros?' punchline='¡Porque era excepcional en su campo!' language='Spanish'\n",
      "French translation as Joke: joke=\"Pourquoi l'épouvantail a-t-il gagné un prix ?\" punchline=\"Parce qu'il était exceptionnel dans son champ !\" language='French'\n",
      "joke=\"Pourquoi l'épouvantail a-t-il gagné un prix ?\" punchline=\"Parce qu'il était exceptionnel dans son champ !\" language='French'\n"
     ]
    }
   ],
   "source": [
    "input_list = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a dad joke\"},\n",
    "]\n",
    "\n",
    "\n",
    "with trace(\"dad_jokes_agent_manual_handoff\", group_id=\"dad_jokes\") as tr:\n",
    "\n",
    "    print(f\"Trace URL: {get_trace_url(tr)}\")\n",
    "\n",
    "    run_output = await Runner.run(\n",
    "        starting_agent= dad_jokes_agent,\n",
    "        input=input_list,\n",
    "        run_config = RunConfig(\n",
    "            model_provider=GITHUB_MODEL_PROVIDER,\n",
    "            model = model_name,\n",
    "        ),\n",
    "        )\n",
    "\n",
    "\n",
    "    print(run_output)\n",
    "\n",
    "    # joke_output : Joke = run_output.final_output\n",
    "    # print(f\"Joke: {joke_output.joke}\")\n",
    "    print(f\"First joke as Joke: {run_output.final_output_as(Joke)}\")\n",
    "\n",
    "\n",
    "    next_input = run_output.to_input_list()\n",
    "    next_input.append(handoff_instructions_msg(\"Spanish\"))\n",
    "\n",
    "    spanish_agent.output_type = Joke\n",
    "    spanish_output = await Runner.run(\n",
    "        starting_agent=spanish_agent,\n",
    "        input=next_input,\n",
    "        run_config = RunConfig(\n",
    "            model_provider=GITHUB_MODEL_PROVIDER,\n",
    "            model = model_name,\n",
    "        ),\n",
    "        )\n",
    "\n",
    "    print(f\"Spanish translation as Joke: {spanish_output.final_output_as(Joke)}\")\n",
    "\n",
    "\n",
    "    french_agent.output_type = Joke\n",
    "    french_agent_input = spanish_output.to_input_list()\n",
    "    french_agent_input.append(handoff_instructions_msg(\"French\"))\n",
    "    french_output = await Runner.run(\n",
    "        starting_agent=french_agent,\n",
    "        input=french_agent_input,\n",
    "        run_config = RunConfig(\n",
    "            model_provider=GITHUB_MODEL_PROVIDER,\n",
    "            model = model_name,\n",
    "        ),\n",
    "        )\n",
    "\n",
    "\n",
    "    print(f\"French translation as Joke: {french_output.final_output_as(Joke)}\")\n",
    "\n",
    "    french_output.to_input_list()\n",
    "\n",
    "\n",
    "print(french_output.final_output_as(Joke))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f7b7d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='{\"joke\":\"Pourquoi l\\'épouvantail a-t-il gagné un prix ?\",\"punchline\":\"Parce qu\\'il était exceptionnel dans son champ !\",\"language\":\"French\"}', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=241, output_tokens=37, total_tokens=278), referenceable_id=None)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Tell me a dad joke'},\n",
       " {'id': '__fake_id__',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': '{\"joke\":\"Why did the scarecrow win an award?\",\"punchline\":\"Because he was outstanding in his field!\",\"language\":\"English\"}',\n",
       "    'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'},\n",
       " {'role': 'user', 'content': 'Translate the following text to Spanish'},\n",
       " {'id': '__fake_id__',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': '{\"joke\":\"¿Por qué ganó un premio el espantapájaros?\",\"punchline\":\"¡Porque era excepcional en su campo!\",\"language\":\"Spanish\"}',\n",
       "    'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'},\n",
       " {'role': 'user', 'content': 'Translate the following text to French'},\n",
       " {'id': '__fake_id__',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': '{\"joke\":\"Pourquoi l\\'épouvantail a-t-il gagné un prix ?\",\"punchline\":\"Parce qu\\'il était exceptionnel dans son champ !\",\"language\":\"French\"}',\n",
       "    'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(french_output.raw_responses)\n",
    "\n",
    "next_input = french_output.to_input_list()\n",
    "display(next_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6f34f",
   "metadata": {},
   "source": [
    "# Implement Handoffs\n",
    "\n",
    "In this example, we will implement the handoffs using the SDK handoff functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba403cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_response_agent = Agent(\n",
    "    name=\"user_response_agent\",\n",
    "    instructions=\"\"\"\n",
    "        You are an agent that generates a response to the user's message.\n",
    "        your response should include summary of steps taken to produce the final output\n",
    "        in bullet points.\n",
    "        present this execution summary as a list of steps taken to produce the final output.\"\n",
    "        then in the response back to the user, include the final output from each step,\n",
    "        the user query, and the very last final output\"\n",
    "    \"\"\",\n",
    "    handoff_description=\"\"\"\n",
    "    An agent capable of generating final user responses\n",
    "    Final user response is a summary of the steps taken to produce the final output.\n",
    "    \"\"\",\n",
    "    model=model_name,\n",
    "    output_type=str,\n",
    ")\n",
    "\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"orchestrator_agent\",\n",
    "    model=model_name,\n",
    "    tool_use_behavior=\"run_llm_again\",\n",
    "    instructions=\"\"\"\n",
    "        You are an orchestrator agent.\n",
    "        You breakdown the task to multiple steps and handoff to appropriate agents.\n",
    "        You are capable of generating jokes, translating messages to Spanish and French.\n",
    "        If asked for multiple translations, handoff to multiple language agents.\n",
    "        You only speak English. Do not translate the user's message yourself.\n",
    "        Use translator only when you have content to be translated, otherwise, handoff to the next agent.\n",
    "        ## IMPORTANT ##\n",
    "        Express your thoughts before executing the next step\n",
    "    \"\"\",\n",
    "    handoff_description=(\n",
    "        \"An agent that orchestrates tasks.\"\n",
    "        ),\n",
    "    # handoffs=[dad_jokes_agent,user_response_agent]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# # orchestrator_agent.handoffs = [dad_jokes_agent,user_response_agent]\n",
    "# dad_jokes_agent.handoffs = [spanish_agent, french_agent, user_response_agent]\n",
    "# spanish_agent.handoffs = [user_response_agent]\n",
    "# french_agent.handoffs = [user_response_agent]\n",
    "\n",
    "dad_jokes_agent.handoffs = [\n",
    "    handoff(orchestrator_agent),\n",
    "    # spanish_agent,\n",
    "    # french_agent,\n",
    "    ]\n",
    "\n",
    "spanish_agent.handoffs = [handoff(orchestrator_agent)]\n",
    "\n",
    "orchestrator_agent.handoffs = [\n",
    "    dad_jokes_agent,\n",
    "    spanish_agent,\n",
    "    user_response_agent,\n",
    "    ]\n",
    "\n",
    "\n",
    "# # Handoff callback that processes the escalation data\n",
    "async def process_handoff(ctx: RunContextWrapper, input_data: Joke):\n",
    "   print(f\"[handoff] Joke: {input_data.joke}\")\n",
    "   print(f\"[handoff] Punchline: {input_data.punchline}\")\n",
    "   print(f\"[handoff] Language: {input_data.language}\")\n",
    "\n",
    "\n",
    "# dad_jokes_agent.handoffs = [\n",
    "#    handoff(\n",
    "#          agent=spanish_agent,\n",
    "#          input_type=Joke,\n",
    "#          on_handoff=process_handoff,\n",
    "#    ),\n",
    "#    handoff(\n",
    "#          agent=french_agent,\n",
    "#          input_type=Joke,\n",
    "#          on_handoff=process_handoff,\n",
    "#    ),\n",
    "#     handoff(\n",
    "#             agent=user_response_agent,\n",
    "#             input_type=Joke,\n",
    "#             on_handoff=process_handoff,\n",
    "#     ),\n",
    "# ]\n",
    "\n",
    "\n",
    "try:\n",
    "    gv = draw_graph(\n",
    "        orchestrator_agent,\n",
    "        filename=\"./viz/07_agent_handoffs_orchestrator_agent.gv\",\n",
    "\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57151ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Handoff(tool_name='transfer_to_orchestrator_agent', tool_description='Handoff to the orchestrator_agent agent to handle the request. An agent that orchestrates tasks.', input_json_schema={'additionalProperties': False, 'type': 'object', 'properties': {}, 'required': []}, on_invoke_handoff=<function handoff.<locals>._invoke_handoff at 0x000002644B9F2320>, agent_name='orchestrator_agent', input_filter=None, strict_json_schema=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orchestrator_agent.handoffs\n",
    "len(dad_jokes_agent.handoffs)\n",
    "dad_jokes_agent.handoffs[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646b638",
   "metadata": {},
   "source": [
    "# Implementing Agent Handoffs with the Agents SDK\n",
    "\n",
    "![handoff flow](./viz/07_agent_handoffs_orchestrator_agent.svg)\n",
    "\n",
    "This visualization shows the agent flow we've created, where the orchestrator agent directs requests to the appropriate specialized agents. The dad jokes generator produces jokes, which can then be handed off to language agents (Spanish or French) for translation, and finally to the user response agent to format the final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "412fe1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace URL: https://platform.openai.com/traces/trace?trace_id=trace_b3ca8cd78c2e4f11a1fa14b0579b026a\n",
      "Error: Max turns (10) exceeded\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "\n",
    "msg = input (\"Enter your message: \") or \"Hello, tell me a joke about chickens in spanish\"\n",
    "\n",
    "inputs: list[TResponseInputItem] = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "result = None\n",
    "try:\n",
    "    with trace(workflow_name=\"handoffs\", group_id=\"mdsi\") as tr:\n",
    "        print(f\"Trace URL: {get_trace_url(tr)}\")\n",
    "        result = await Runner.run(\n",
    "            starting_agent=orchestrator_agent,\n",
    "            input=inputs,\n",
    "            run_config=RunConfig(\n",
    "                model=model_name,\n",
    "                model_provider=GITHUB_MODEL_PROVIDER,\n",
    "                model_settings=ModelSettings(\n",
    "                    temperature=0.5,\n",
    "                    max_tokens=5000,\n",
    "                ),\n",
    "                ),\n",
    "\n",
    "            max_turns=10\n",
    "        )\n",
    "\n",
    "        print(result.final_output)\n",
    "        # print(result.last_agent)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bd6cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunResult:\n",
      "- Last agent: Agent(name=\"Spanish agent\", ...)\n",
      "- Final output (Joke):\n",
      "    {\n",
      "      \"joke\": \"¿Por qué los pájaros no usan Facebook?\",\n",
      "      \"punchline\": \"Porque ya tienen Twitter.\",\n",
      "      \"language\": \"español\"\n",
      "    }\n",
      "- 14 new item(s)\n",
      "- 6 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n",
      "https://platform.openai.com/traces/trace?trace_id=trace_5e57bf4fc1424924a24b76ede78925b4\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "\n",
    "print(get_trace_url(tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06900f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.raw_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.trace_util import display_agent_execution_steps\n",
    "\n",
    "\n",
    "display_agent_execution_steps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracing_url = f\"https://platform.openai.com/traces/trace?trace_id={tr.trace_id}\"\n",
    "\n",
    "print(f\"Tracing URL: {tracing_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac50a878",
   "metadata": {},
   "source": [
    "## Visualise the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.visualization import draw_graph\n",
    "\n",
    "try:\n",
    "    draw_graph(orchestrator_agent, filename=\"viz/07_agent_handoffs.gv\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd1ad9",
   "metadata": {},
   "source": [
    "# another explains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "french_agent = Agent(\n",
    "    name=\"french_agent\",\n",
    "    instructions=\"You only speak French\",\n",
    ")\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"spanish_agent\",\n",
    "    instructions=\"You only speak Spanish\",\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"english_agent\",\n",
    "    instructions=\"You only speak English\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"triage_agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[french_agent, spanish_agent, english_agent],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.responses import ResponseContentPartDoneEvent, ResponseTextDeltaEvent\n",
    "\n",
    "from agents import Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "import uuid\n",
    "\n",
    "conversation_id = str(uuid.uuid4().hex[:16])\n",
    "\n",
    "msg = input(\"Hi! We speak French, Spanish and English. How can I help? \")\n",
    "agent = triage_agent\n",
    "inputs: list[TResponseInputItem] = []\n",
    "inputs.append({\"content\": msg, \"role\": \"user\"})\n",
    "\n",
    "while True:\n",
    "    # Each conversation turn is a single trace. Normally, each input from the user would be an\n",
    "    # API request to your app, and you can wrap the request in a trace()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with trace(\"Routing example\", group_id=conversation_id):\n",
    "        result = Runner.run_streamed(\n",
    "            agent,\n",
    "            input=inputs,\n",
    "            run_config=RunConfig(model=model_name, model_provider=GITHUB_MODEL_PROVIDER),\n",
    "        )\n",
    "        async for event in result.stream_events():\n",
    "            if not isinstance(event, RawResponsesStreamEvent):\n",
    "                continue\n",
    "            data = event.data\n",
    "            if isinstance(data, ResponseTextDeltaEvent):\n",
    "                print(data.delta, end=\"\", flush=True)\n",
    "            elif isinstance(data, ResponseContentPartDoneEvent):\n",
    "                print(\"\\n\")\n",
    "\n",
    "    inputs = result.to_input_list()\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    agent = result.current_agent\n",
    "    user_msg = input(\"Enter a message: \")\n",
    "    if user_msg in (\"exit\", \"quit\", \"\"):\n",
    "        break\n",
    "    inputs.append({\"content\": user_msg, \"role\": \"user\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29104308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    draw_graph(orchestrator_agent, filename=\"viz/07_agent_handoffs.gv\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
