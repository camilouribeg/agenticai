{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d6b2f64",
   "metadata": {},
   "source": [
    "# Function Calling \n",
    "\n",
    "The LLM models are limited to generation based on knowledge included in their training data or context information provided in the prompt (see RAG concepts). \n",
    "\n",
    "However, function calling allows the model extend it's capabilities and request to invoke function to perform specific tasks or retrieve information. \n",
    "\n",
    "This is particularly useful for tasks that require structured data or specific actions, such as retrieving information from a database or performing calculations.\n",
    "\n",
    "\n",
    "References: \n",
    "- https://platform.openai.com/docs/guides/function-calling\n",
    "- https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9b24fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "from agents import (\n",
    "    Agent,\n",
    "    Runner,\n",
    "    OpenAIChatCompletionsModel,\n",
    "    ModelProvider,\n",
    "    Model,\n",
    "    RunConfig,\n",
    "    set_default_openai_client,\n",
    "    set_default_openai_api,\n",
    "    set_tracing_disabled,\n",
    "    function_tool,\n",
    ")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "821371a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    ")\n",
    "\n",
    "client2 = OpenAI(\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "addbb6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message(role, content):\n",
    "    return {\"role\": role, \"content\":\n",
    "            [{\n",
    "                \"type\": \"text\",\n",
    "                \"text\": content}]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba1ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    message(\"developer\", \"you are a helpful assistant\"),\n",
    "    message(\"user\", \"How is the weather in Sydney today?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6558064",
   "metadata": {},
   "source": [
    "## Standard Chat Completions call \n",
    "\n",
    "LLM has no context of realtime data or information not currently in its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f59a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"I'm unable to provide real-time weather updates. I recommend checking a reliable weather website or using a weather app for the most current information on Sydney's weather.\",\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "completion = await client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages)\n",
    "\n",
    "\n",
    "\n",
    "print(completion.choices[0].message.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73592dec",
   "metadata": {},
   "source": [
    "## Function Calling Example \n",
    "\n",
    "The flow of function calling is as follows:\n",
    "\n",
    "<img src=\"https://cdn.openai.com/API/docs/images/function-calling-diagram-steps.png\" alt=\"Function Calling\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0280c8f",
   "metadata": {},
   "source": [
    "### Define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcfc76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weather_function_definition = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\":{\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather in a given city\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the location to get the weather for\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "            \"additionalProperties\": False,\n",
    "\n",
    "        },\n",
    "    },\n",
    "    \"strict\": True\n",
    "}\n",
    "\n",
    "tools = [get_weather_function_definition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b8bc823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location):\n",
    "    # return f\"The weather in {location} is sunny with a high of 25Â°C.\"\n",
    "    return {\"temperature\": 25, \"condition\": \"sunny\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f680af",
   "metadata": {},
   "source": [
    "### 1. Send messasge with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fbeb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = messages\n",
    "completion = await client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=chat_history,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d466b",
   "metadata": {},
   "source": [
    "### 2. Model responsds with function call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cdde083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": null,\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\",\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"id\": \"call_A0GbXBeZGkAR1ooDoMKQCPcs\",\n",
      "      \"function\": {\n",
      "        \"arguments\": \"{\\\"location\\\":\\\"Sydney\\\"}\",\n",
      "        \"name\": \"get_weather\"\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# print(completion.to_json())\n",
    "\n",
    "print(completion.choices[0].message.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663d650",
   "metadata": {},
   "source": [
    "must append the function call request to the message history, then perform the requested function call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64726090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'developer',\n",
       "  'content': [{'type': 'text', 'text': 'you are a helpful assistant'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'How is the weather in Sydney today?'}]},\n",
       " {'content': None,\n",
       "  'refusal': None,\n",
       "  'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_A0GbXBeZGkAR1ooDoMKQCPcs',\n",
       "    'function': {'arguments': '{\"location\":\"Sydney\"}', 'name': 'get_weather'},\n",
       "    'type': 'function'}]}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(json.loads(completion.choices[0].message.to_json()))  # append model's function call message\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b013de3",
   "metadata": {},
   "source": [
    "### 3. Execute Function call \n",
    "\n",
    "Inspect the finish_reson, if it is \"tool_calls\", then proceed to execute the request function with arguments specified by the LLM function call request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79e3f0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_calls\n",
      "{\n",
      "  \"id\": \"call_A0GbXBeZGkAR1ooDoMKQCPcs\",\n",
      "  \"function\": {\n",
      "    \"arguments\": \"{\\\"location\\\":\\\"Sydney\\\"}\",\n",
      "    \"name\": \"get_weather\"\n",
      "  },\n",
      "  \"type\": \"function\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "finish_reason = completion.choices[0].finish_reason\n",
    "print(finish_reason)\n",
    "tool_calls = completion.choices[0].message.tool_calls\n",
    "print(tool_calls[0].to_json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae59bd3",
   "metadata": {},
   "source": [
    "Execute the fucntion, and append function call result to the message history. Must tool_call_id returned by the LLM function call request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a33da26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_A0GbXBeZGkAR1ooDoMKQCPcs\n",
      "get_weather\n",
      "{\"location\":\"Sydney\"}\n",
      "{'temperature': 25, 'condition': 'sunny'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tool in tool_calls:\n",
    "    print(tool.id)\n",
    "    print(tool.function.name)\n",
    "    print(tool.function.arguments)\n",
    "    function_name = tool.function.name\n",
    "    function_args = json.loads(tool.function.arguments)\n",
    "    tool_call_id = tool.id\n",
    "\n",
    "\n",
    "\n",
    "    # execute the function call and append the results as a ToolMessage in the message history\n",
    "    function_call_results = locals()[function_name](**function_args)\n",
    "    print(function_call_results)\n",
    "    function_call_results_message = {\n",
    "        \"role\": \"tool\",\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"tool_call_id\": tool_call_id,\n",
    "        \"content\": str(function_call_results)\n",
    "    }\n",
    "\n",
    "\n",
    "    chat_history.append(function_call_results_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ee142ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'temperature': 25, 'condition': 'sunny'}\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(function_call_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c2d7e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'developer',\n",
       "  'content': [{'type': 'text', 'text': 'you are a helpful assistant'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'How is the weather in Sydney today?'}]},\n",
       " {'content': None,\n",
       "  'refusal': None,\n",
       "  'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_A0GbXBeZGkAR1ooDoMKQCPcs',\n",
       "    'function': {'arguments': '{\"location\":\"Sydney\"}', 'name': 'get_weather'},\n",
       "    'type': 'function'}]},\n",
       " {'role': 'tool',\n",
       "  'type': 'function_call_output',\n",
       "  'tool_call_id': 'call_A0GbXBeZGkAR1ooDoMKQCPcs',\n",
       "  'content': \"{'temperature': 25, 'condition': 'sunny'}\"}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796b787",
   "metadata": {},
   "source": [
    "### 4. Send the result back to the model\n",
    "\n",
    "Send the result of the function call back to the model as a message. This message should include the function call result and message history. Function call result must correctly include tool_call_id, so that the model can match the result with the original function call request.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a02e0ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = await client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=chat_history,\n",
    "    tools=tools\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0782bf",
   "metadata": {},
   "source": [
    "### 5. Model final response \n",
    "\n",
    "\n",
    "The model will then respond with a message that includes the result of the function call. This message can be used to continue the conversation or provide additional information to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca1563a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Sydney today is sunny with a temperature of 25Â°C.\n"
     ]
    }
   ],
   "source": [
    "print(response_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40b9dad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"The weather in Sydney today is sunny with a temperature of 25Â°C.\",\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response_2.choices[0].message.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b80cee",
   "metadata": {},
   "source": [
    "### 6. Continue the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb2a0f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"Ø§ÙØ·ÙØ³ ÙÙ Ø³ÙØ¯ÙÙ Ø§ÙÙÙÙ ÙØ´ÙØ³ ÙØ¯Ø±Ø¬Ø© Ø§ÙØ­Ø±Ø§Ø±Ø© 25Â°C.\",\n",
      "  \"refusal\": null,\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# always append model response to the chat history\n",
    "chat_history.append(json.loads(response_2.choices[0].message.to_json()))  # append model's function call message\n",
    "# new user message\n",
    "chat_history.append(message(\"user\", \"what again in Arabic please?\"))\n",
    "response_3 = await client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=chat_history,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "\n",
    "print(response_3.choices[0].message.to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
