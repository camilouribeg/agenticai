{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add tracing using mlflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mlflow.org/docs/latest/tracing/integrations/openai-agent\n",
    "# https://openai.github.io/openai-agents-python/tracing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9bb277cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import (\n",
    "    Agent,\n",
    "    Runner,\n",
    "    OpenAIChatCompletionsModel,\n",
    "    ModelProvider,\n",
    "    Model,\n",
    "    RunConfig,\n",
    "    set_default_openai_client, \n",
    "    set_default_openai_api,\n",
    "    set_tracing_disabled,\n",
    "    function_tool,\n",
    ")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc9cfd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    ")\n",
    "\n",
    "set_default_openai_client(client)\n",
    "set_default_openai_api(\n",
    "    ['chat_completions']\n",
    ")\n",
    "set_tracing_disabled(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f12b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def get_weather(city: str):\n",
    "    print(f\"[debug] getting weather for {city}\")\n",
    "    return f\"The weather in {city} is ......\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2372a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GitHubModelProvider(ModelProvider):\n",
    "    def get_model(self, model_name) -> Model:\n",
    "        return OpenAIChatCompletionsModel(model=\"gpt-4o\", openai_client=client)\n",
    "\n",
    "GITHUB_MODEL_PROVIDER = GitHubModelProvider()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7987428",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"Assistant\", \n",
    "    instructions=\"Answer the user's questions.\",\n",
    "    tools=[get_weather],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9fa43712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This example uses a custom provider for some calls to Runner.run(), and direct calls to OpenAI for\\nothers. Steps:\\n1. Create a custom OpenAI client.\\n2. Create a ModelProvider that uses the custom client.\\n3. Use the ModelProvider in calls to Runner.run(), only when we want to use the custom LLM provider.\\n\\nNote that in this example, we disable tracing under the assumption that you don't have an API key\\nfrom platform.openai.com. If you do have one, you can either set the `OPENAI_API_KEY` env var\\nor call set_tracing_export_api_key() to set a tracing specific key.\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"This example uses a custom provider for some calls to Runner.run(), and direct calls to OpenAI for\n",
    "others. Steps:\n",
    "1. Create a custom OpenAI client.\n",
    "2. Create a ModelProvider that uses the custom client.\n",
    "3. Use the ModelProvider in calls to Runner.run(), only when we want to use the custom LLM provider.\n",
    "\n",
    "Note that in this example, we disable tracing under the assumption that you don't have an API key\n",
    "from platform.openai.com. If you do have one, you can either set the `OPENAI_API_KEY` env var\n",
    "or call set_tracing_export_api_key() to set a tracing specific key.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3586aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] getting weather for New York\n",
      "The weather in New York is cloudy, with occasional rainfall.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/openai/openai-agents-python/blob/main/examples/model_providers/custom_example_provider.py\n",
    "result = await Runner.run(\n",
    "    agent, \n",
    "    \"What is the weather in New York?\", \n",
    "    run_config=RunConfig(model_provider=GITHUB_MODEL_PROVIDER),\n",
    ")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ae336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf42f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
