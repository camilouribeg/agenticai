{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "863b46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mlflow.org/docs/latest/tracing/integrations/openai-agent\n",
    "# https://openai.github.io/openai-agents-python/tracing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb277cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import (\n",
    "\n",
    "    Agent,\n",
    "    Runner,\n",
    "    OpenAIChatCompletionsModel,\n",
    "    ModelProvider,\n",
    "    Model,\n",
    "    RunConfig,\n",
    "    set_default_openai_client, \n",
    "    set_default_openai_api,\n",
    "    set_tracing_disabled,\n",
    "    set_tracing_export_api_key,\n",
    "    trace,\n",
    "    \n",
    "\n",
    "    function_tool,\n",
    ")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9cfd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    ")\n",
    "\n",
    "set_default_openai_client(client)\n",
    "set_default_openai_api(\n",
    "    ['chat_completions']\n",
    ")\n",
    "set_tracing_export_api_key(os.environ[\"OPENAI_TRACING_KEY\"])\n",
    "set_tracing_disabled(False)\n",
    "\n",
    "# tr = trace(workflow_name=\"msdiagentic_hello_tracking\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d46457d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f12b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# TODO: add a strongly typed return value for the get_weather function \n",
    "# exmple: def get_weather(city: str) -> WeatherInfo:\n",
    "# https://github.com/openai/openai-agents-python/blob/main/examples/basic/tools.py\n",
    "\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    city: str\n",
    "    temperature: str\n",
    "    conditions: str\n",
    "\n",
    "\n",
    "class CurrentTime(BaseModel):\n",
    "    location: str = Field(..., description=\"The name of the location\")\n",
    "    current_time: str = Field(..., description=\"The current time in the location\")\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str):\n",
    "    print(f\"[debug] getting weather for {city}\")\n",
    "    temperature = f\"{random.randint(-10, 50)}C\"\n",
    "    conditions = random.choice([\"Sunny\", \"Windy\", \"Rainy\", \"Cloudy\"])\n",
    "    return Weather(city=city, temperature=temperature, conditions=conditions)  \n",
    "\n",
    "@function_tool\n",
    "def get_current_time(location):\n",
    "    from datetime import datetime\n",
    "    \"\"\"Get the current time for a given location\"\"\"\n",
    "    print(f\"[debug] get_current_time called with location: {location}\")\n",
    "    location_lower = location.lower()\n",
    "\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%I:%M %p\")\n",
    "    return CurrentTime(\n",
    "        location=location,\n",
    "        current_time=current_time,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2372a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GitHubModelProvider(ModelProvider):\n",
    "    def get_model(self, model_name) -> Model:\n",
    "        return OpenAIChatCompletionsModel(model=\"gpt-4o\", openai_client=client)\n",
    "\n",
    "GITHUB_MODEL_PROVIDER = GitHubModelProvider()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7987428",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"Assistant\", \n",
    "    instructions=\"Answer the user's questions.\",\n",
    "    tools=[get_weather, get_current_time],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fa43712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This example uses a custom provider for some calls to Runner.run(), and direct calls to OpenAI for\\nothers. Steps:\\n1. Create a custom OpenAI client.\\n2. Create a ModelProvider that uses the custom client.\\n3. Use the ModelProvider in calls to Runner.run(), only when we want to use the custom LLM provider.\\n\\nNote that in this example, we disable tracing under the assumption that you don't have an API key\\nfrom platform.openai.com. If you do have one, you can either set the `OPENAI_API_KEY` env var\\nor call set_tracing_export_api_key() to set a tracing specific key.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"This example uses a custom provider for some calls to Runner.run(), and direct calls to OpenAI for\n",
    "others. Steps:\n",
    "1. Create a custom OpenAI client.\n",
    "2. Create a ModelProvider that uses the custom client.\n",
    "3. Use the ModelProvider in calls to Runner.run(), only when we want to use the custom LLM provider.\n",
    "\n",
    "Note that in this example, we disable tracing under the assumption that you don't have an API key\n",
    "from platform.openai.com. If you do have one, you can either set the `OPENAI_API_KEY` env var\n",
    "or call set_tracing_export_api_key() to set a tracing specific key.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3586aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] getting weather for New York\n",
      "[debug] get_current_time called with location: New York\n",
      "The weather in New York is currently 5Â°C and cloudy. The time in New York is 01:46 AM.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/openai/openai-agents-python/blob/main/examples/model_providers/custom_example_provider.py\n",
    "\n",
    "with trace(workflow_name=\"msdiagentic_hello_tracking\"):\n",
    "    result = await Runner.run(\n",
    "        agent, \n",
    "        \"What is the weather in New York? And what is the time?\", \n",
    "        run_config=RunConfig(model_provider=GITHUB_MODEL_PROVIDER),\n",
    "        \n",
    "    )\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce73a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace workflow name: Dummy_20250330_014641\n",
      "Trace ID: trace_094ade8170f9482a92af5991fb0d9fdd\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "tr = trace(\n",
    "    workflow_name=f\"Dummy_{timestamp}\",\n",
    "    group_id=\"Dummy Group\", \n",
    "    metadata={\n",
    "        \"key1\": \"value1\",\n",
    "        \"key2\": \"value2\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# print trace workflow name\n",
    "print(f\"Trace workflow name: {tr.name}\")\n",
    "tr.start()\n",
    "\n",
    "trace_id = tr.trace_id\n",
    "print(f\"Trace ID: {trace_id}\")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    model_provider=GITHUB_MODEL_PROVIDER,\n",
    "    trace_id=trace_id,  # Pass the trace ID to the run config\n",
    "    trace_metadata={\"AgentName\": \"WeatherAgent\"}, \n",
    "    workflow_name=tr.name,  # Pass the workflow name to the run config\n",
    "    group_id=tr.group_id,  # Pass the group ID to the run config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812737e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] getting weather for New York\n",
      "[debug] get_current_time called with location: New York\n",
      "The weather in New York is currently 14Â°C and rainy. The time in New York is 01:46 AM.\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "        agent, \n",
    "        \"What is the weather in New York? And time.\", \n",
    "        run_config=run_config,\n",
    "    )\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a427c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] get_current_time called with location: Sydney\n",
      "The current time in Sydney is 1:47 AM.\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "        agent, \n",
    "        \"What is the time in Sydney\", \n",
    "        run_config=run_config,\n",
    "    )\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1368918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's one for you:\n",
      "\n",
      "Why don't skeletons fight each other?\n",
      "\n",
      "Because they don't have the guts! ðŸ˜„\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "        agent, \n",
    "        \"Tell me a joke!\", \n",
    "        run_config=run_config,\n",
    "    )\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebcf5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4339e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing URL: https://platform.openai.com/traces/trace?trace_id=trace_094ade8170f9482a92af5991fb0d9fdd\n"
     ]
    }
   ],
   "source": [
    "tracing_url = f\"https://platform.openai.com/traces/trace?trace_id={trace_id}\"\n",
    "\n",
    "print(f\"Tracing URL: {tracing_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9068b",
   "metadata": {},
   "source": [
    "View Traces [here](https://platform.openai.com/traces?group_id=Dummy+Group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2531f",
   "metadata": {},
   "source": [
    "# Add Viz\n",
    "\n",
    "requires GraphViz extension to view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6857f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH\n"
     ]
    }
   ],
   "source": [
    "from agents.extensions.visualization import draw_graph\n",
    "\n",
    "try:\n",
    "    draw_graph(agent, filename=\"agent_graph.gv\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
