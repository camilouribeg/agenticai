{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe52035e",
   "metadata": {},
   "source": [
    "https://github.com/openai/openai-agents-python/blob/main/examples/basic/agent_lifecycle_example.py \n",
    "\n",
    "two agents\n",
    "each has its own tools \n",
    "\n",
    "1. starter agents: will process the initial user request, will use tools as needed and will handoff to other agents if required\n",
    "2. multiply agent: knows how to perform arithmetic operations (can we configure a handoff)\n",
    "\n",
    "example also keeps tracks of agent life cycle events \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0c45d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import (\n",
    "\n",
    "    Agent,\n",
    "    Runner,\n",
    "    RunConfig,\n",
    "    trace,\n",
    ")\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467e7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "from helpers.trace_util import get_trace_url\n",
    "from agents.extensions.visualization import draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00e1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.model_client import (\n",
    "    get_openai_client,\n",
    "    get_github_model_provider\n",
    ")\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "GITHUB_MODEL_PROVIDER = get_github_model_provider(\n",
    "    client = get_openai_client(),\n",
    "    model = model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c7ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "from agents import handoff, RunContextWrapper\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str = Field(description=\"The joke text\")\n",
    "    punchline: str = Field(description=\"The punchline of the joke\")\n",
    "    language: str = Field(description=\"The language of the joke\")\n",
    "    spanish_translation: str = Field(description=\"The joke translated to Spanish\")\n",
    "    french_translation: str = Field(description=\"The joke translated to French\")\n",
    "\n",
    "\n",
    "# class Translation(BaseModel):\n",
    "#     content: str = Field(description=\"Content\")\n",
    "#     language: str = Field(description=\"The language of the translation\")\n",
    "\n",
    "# async def on_handoff1(ctx: RunContextWrapper[None], input_data: Translation):\n",
    "#     print(f\"agent {ctx} called with: {input_data.content}\")\n",
    "\n",
    "dad_jokes_agent = Agent(\n",
    "    name=\"dad_jokes_generator_agent\",\n",
    "    instructions=(\n",
    "        f\"{RECOMMENDED_PROMPT_PREFIX} \\n\"\n",
    "        \"You are an agent that specialises in generating jokes, dad jokes specifically. \"\n",
    "        \"You only respond with dad jokes.\"\n",
    "        \"You do not answer any other questions. \"\n",
    "        \"Return the job to the orchestrator agent once you produced the joke \"\n",
    "        \"always deliver a punchline. \"\n",
    "        \" ## IMPORTANT ##\"\n",
    "        \"Always respond in English, even if the user asks in a different language. \"\n",
    "        \"You are not allowed to use any other language than English. \"\n",
    "        \"You are not allowed to end the conversation, must handoff to an approriate agent.\"\n",
    "    ),\n",
    "    handoff_description=(\n",
    "        \"An agent capable of generating jokes based on user input \"\n",
    "        \"you only generate content in English, regardless of the input language, or user requested language\"\n",
    "    ),\n",
    "    model=model_name,\n",
    "    output_type=Joke,\n",
    ")\n",
    "\n",
    "\n",
    "spanish_agent = Agent[Joke](\n",
    "    name=\"spanish_agent\",\n",
    "    instructions= (\n",
    "        f\"{RECOMMENDED_PROMPT_PREFIX} \\n\"\n",
    "        \"You translate the input message to Spanish\"\n",
    "        \"You only translate, you dont generate new content\"\n",
    "        \"handoff the job back to the orchestrator once you produced the translation\"\n",
    "        \"if you cannot answer, transfer back to the orchestrator\"\n",
    "    ),\n",
    "    handoff_description=\"An agent capable of translating messages to Spanish\",\n",
    "    model=model_name,\n",
    "    output_type=Joke,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "french_agent = Agent[Joke](\n",
    "    name=\"french_agent\",\n",
    "    instructions= (\n",
    "        f\"{RECOMMENDED_PROMPT_PREFIX} \\n\"\n",
    "        \"You translate the user's message to French\"\n",
    "        \"you only translate, you dont generate new content\"\n",
    "        \"handoff the job back to the orchestrator once you produced the translation\"\n",
    "        \"if you cannot answer, transfer back to the orchestrator\"\n",
    "    ),\n",
    "    handoff_description=\"An agent capable of translating messages to French\",\n",
    "    model=model_name,\n",
    "    output_type=Joke,\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d568294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def handoff_instructions_msg(lang: str):\n",
    "    return {\"role\": \"user\", \"content\": f\"Translate the following text to {lang}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8fb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a dad joke\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6f34f",
   "metadata": {},
   "source": [
    "# Implement Handoffs\n",
    "\n",
    "In this example, we will implement the handoffs using the SDK handoff functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba403cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_response_agent = Agent[Joke](\n",
    "    name=\"user_response_agent\",\n",
    "    instructions=(\n",
    "        f\"{RECOMMENDED_PROMPT_PREFIX} \\n\"\n",
    "        \"You are an agent that generates a response to the user's message.\"\n",
    "        \"your response should include summary of steps taken to produce the final output  in bullet points\"\n",
    "        \"present this execution summary as a list of steps taken to produce the final output.\"\n",
    "        \"then in the response back to the user, include the final output from each step, and the very last final output\"\n",
    "    ),\n",
    "    handoff_description=\"An agent capable of generating final user responses\",\n",
    "    model=model_name,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f9f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orchestrator_agent = Agent[Joke](\n",
    "    name=\"orchestrator_agent\",\n",
    "    model=model_name,\n",
    "    tool_use_behavior=\"run_llm_again\",\n",
    "    instructions=(\n",
    "        f\"{RECOMMENDED_PROMPT_PREFIX} \\n\"\n",
    "        \"You are an orchestrator agent. \"\n",
    "        \"You handoff the task to the appropriate task agent.\"\n",
    "        \"The task agents are: \"\n",
    "        f\"{dad_jokes_agent.name}, {spanish_agent.name}, {french_agent.name}, {user_response_agent.name}.\"\n",
    "        \"You may need to breakdown the task and manage multiple handoffs as needed.\"\n",
    "        \"If asked for multiple translations, handoff to multiple agents.\"\n",
    "        \"You only speak English. Do not translate the user's message yourself.\"\n",
    "        \"Use the responses from other agents to generate the final response.\"\n",
    "        \"You are not allowed to end the conversation, must handoff to an approriate agent.\"\n",
    "    ),\n",
    "    handoff_description=(\n",
    "        \"An agent that orchestrates the task by indentifing an \"\n",
    "        \"executation plan based on available agents and tools \"\n",
    "        \"and then  handing off to other agents.\"\n",
    "        ),\n",
    "    handoffs=[dad_jokes_agent,spanish_agent, french_agent,user_response_agent],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba404b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dad_jokes_agent.handoffs = [orchestrator_agent]\n",
    "spanish_agent.handoffs = [orchestrator_agent]\n",
    "french_agent.handoffs = [orchestrator_agent]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f0a40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: maximum recursion depth exceeded while calling a Python object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    gv = draw_graph(\n",
    "        orchestrator_agent,\n",
    "        filename=\"./viz/07_agent_handoffs_orchestrator_agent_v2.gv\",\n",
    "\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646b638",
   "metadata": {},
   "source": [
    "# Implementing Agent Handoffs with the Agents SDK\n",
    "\n",
    "![handoff flow](./viz/07_agent_handoffs_orchestrator_agent.svg)\n",
    "\n",
    "This visualization shows the agent flow we've created, where the orchestrator agent directs requests to the appropriate specialized agents. The dad jokes generator produces jokes, which can then be handed off to language agents (Spanish or French) for translation, and finally to the user response agent to format the final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "412fe1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace URL: https://platform.openai.com/traces/trace?trace_id=trace_ab3fa25b89fb4bb2921fb1138829ef38\n",
      "joke='Why did the scarecrow win an award?' punchline='Because he was outstanding in his field!' language='English' spanish_translation='' french_translation=''\n",
      "Agent(name='dad_jokes_generator_agent', instructions='# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n \\nYou are an agent that specialises in generating jokes, dad jokes specifically. You only respond with dad jokes.You do not answer any other questions. Return the job to the orchestrator agent once you produced the joke always deliver a punchline.  ## IMPORTANT ##Always respond in English, even if the user asks in a different language. You are not allowed to use any other language than English. You are not allowed to end the conversation, must handoff to an approriate agent.', handoff_description='An agent capable of generating jokes based on user input you only generate content in English, regardless of the input language, or user requested language', handoffs=[Agent(name='orchestrator_agent', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n \\nYou are an orchestrator agent. You handoff the task to the appropriate task agent.The task agents are: dad_jokes_generator_agent, spanish_agent, french_agent, user_response_agent.You may need to breakdown the task and manage multiple handoffs as needed.If asked for multiple translations, handoff to multiple agents.You only speak English. Do not translate the user's message yourself.Use the responses from other agents to generate the final response.You are not allowed to end the conversation, must handoff to an approriate agent.\", handoff_description='An agent that orchestrates the task by indentifing an executation plan based on available agents and tools and then  handing off to other agents.', handoffs=[..., Agent(name='spanish_agent', instructions='# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n \\nYou translate the input message to SpanishYou only translate, you dont generate new contenthandoff the job back to the orchestrator once you produced the translationif you cannot answer, transfer back to the orchestrator', handoff_description='An agent capable of translating messages to Spanish', handoffs=[...], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], mcp_servers=[], input_guardrails=[], output_guardrails=[], output_type=<class '__main__.Joke'>, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='french_agent', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n \\nYou translate the user's message to Frenchyou only translate, you dont generate new contenthandoff the job back to the orchestrator once you produced the translationif you cannot answer, transfer back to the orchestrator\", handoff_description='An agent capable of translating messages to French', handoffs=[...], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], mcp_servers=[], input_guardrails=[], output_guardrails=[], output_type=<class '__main__.Joke'>, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='user_response_agent', instructions=\"# System context\\nYou are part of a multi-agent system called the Agents SDK, designed to make agent coordination and execution easy. Agents uses two primary abstraction: **Agents** and **Handoffs**. An agent encompasses instructions and tools and can hand off a conversation to another agent when appropriate. Handoffs are achieved by calling a handoff function, generally named `transfer_to_<agent_name>`. Transfers between agents are handled seamlessly in the background; do not mention or draw attention to these transfers in your conversation with the user.\\n \\nYou are an agent that generates a response to the user's message.your response should include summary of steps taken to produce the final output  in bullet pointspresent this execution summary as a list of steps taken to produce the final output.then in the response back to the user, include the final output from each step, and the very last final output\", handoff_description='An agent capable of generating final user responses', handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], mcp_servers=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], mcp_servers=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], mcp_servers=[], input_guardrails=[], output_guardrails=[], output_type=<class '__main__.Joke'>, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "\n",
    "msg = input (\"Enter your message: \") or \"Hello, tell me a joke in spanish\"\n",
    "\n",
    "inputs: list[TResponseInputItem] = [{\"content\": msg, \"role\": \"user\"}]\n",
    "\n",
    "result = None\n",
    "try:\n",
    "    with trace(workflow_name=\"handoffs\", group_id=\"mdsi\") as tr:\n",
    "        print(f\"Trace URL: {get_trace_url(tr)}\")\n",
    "        result = await Runner.run(\n",
    "            starting_agent=orchestrator_agent,\n",
    "            input=inputs,\n",
    "            run_config=RunConfig(model=model_name, model_provider=GITHUB_MODEL_PROVIDER),\n",
    "        )\n",
    "\n",
    "        print(result.final_output)\n",
    "        print(result.last_agent)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)\n",
    "\n",
    "print(get_trace_url(tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06900f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.raw_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.trace_util import display_agent_execution_steps\n",
    "\n",
    "\n",
    "display_agent_execution_steps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracing_url = f\"https://platform.openai.com/traces/trace?trace_id={tr.trace_id}\"\n",
    "\n",
    "print(f\"Tracing URL: {tracing_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac50a878",
   "metadata": {},
   "source": [
    "## Visualise the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.visualization import draw_graph\n",
    "\n",
    "try:\n",
    "    draw_graph(orchestrator_agent, filename=\"viz/07_agent_handoffs.gv\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd1ad9",
   "metadata": {},
   "source": [
    "# another explains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "french_agent = Agent(\n",
    "    name=\"french_agent\",\n",
    "    instructions=\"You only speak French\",\n",
    ")\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"spanish_agent\",\n",
    "    instructions=\"You only speak Spanish\",\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"english_agent\",\n",
    "    instructions=\"You only speak English\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"triage_agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[french_agent, spanish_agent, english_agent],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.responses import ResponseContentPartDoneEvent, ResponseTextDeltaEvent\n",
    "\n",
    "from agents import Agent, RawResponsesStreamEvent, Runner, TResponseInputItem, trace\n",
    "import uuid\n",
    "\n",
    "conversation_id = str(uuid.uuid4().hex[:16])\n",
    "\n",
    "msg = input(\"Hi! We speak French, Spanish and English. How can I help? \")\n",
    "agent = triage_agent\n",
    "inputs: list[TResponseInputItem] = []\n",
    "inputs.append({\"content\": msg, \"role\": \"user\"})\n",
    "\n",
    "while True:\n",
    "    # Each conversation turn is a single trace. Normally, each input from the user would be an\n",
    "    # API request to your app, and you can wrap the request in a trace()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with trace(\"Routing example\", group_id=conversation_id):\n",
    "        result = Runner.run_streamed(\n",
    "            agent,\n",
    "            input=inputs,\n",
    "            run_config=RunConfig(model=model_name, model_provider=GITHUB_MODEL_PROVIDER),\n",
    "        )\n",
    "        async for event in result.stream_events():\n",
    "            if not isinstance(event, RawResponsesStreamEvent):\n",
    "                continue\n",
    "            data = event.data\n",
    "            if isinstance(data, ResponseTextDeltaEvent):\n",
    "                print(data.delta, end=\"\", flush=True)\n",
    "            elif isinstance(data, ResponseContentPartDoneEvent):\n",
    "                print(\"\\n\")\n",
    "\n",
    "    inputs = result.to_input_list()\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    agent = result.current_agent\n",
    "    user_msg = input(\"Enter a message: \")\n",
    "    if user_msg in (\"exit\", \"quit\", \"\"):\n",
    "        break\n",
    "    inputs.append({\"content\": user_msg, \"role\": \"user\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29104308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    draw_graph(orchestrator_agent, filename=\"viz/07_agent_handoffs.gv\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
