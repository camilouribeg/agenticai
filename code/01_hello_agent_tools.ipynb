{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bb277cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import AsyncOpenAI\n",
    "from agents import (\n",
    "    Agent,\n",
    "    Runner,\n",
    "    OpenAIChatCompletionsModel,\n",
    "    ModelProvider,\n",
    "    Model,\n",
    "    RunConfig,\n",
    "    set_default_openai_client, \n",
    "    set_default_openai_api,\n",
    "    set_tracing_disabled,\n",
    "    function_tool,\n",
    ")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9cfd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    ")\n",
    "\n",
    "set_default_openai_client(client)\n",
    "set_default_openai_api(\n",
    "    ['chat_completions']\n",
    ")\n",
    "set_tracing_disabled(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f12b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# TODO: add a strongly typed return value for the get_weather function \n",
    "# exmple: def get_weather(city: str) -> WeatherInfo:\n",
    "# https://github.com/openai/openai-agents-python/blob/main/examples/basic/tools.py\n",
    "\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    city: str\n",
    "    temperature: str\n",
    "    conditions: str\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str):\n",
    "    print(f\"[debug] getting weather for {city}\")\n",
    "    temperature = f\"{random.randint(-10, 50)}C\"\n",
    "    conditions = random.choice([\"Sunny\", \"Windy\", \"Rainy\", \"Cloudy\"])\n",
    "    return Weather(city=city, temperature=temperature, conditions=conditions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2372a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GitHubModelProvider(ModelProvider):\n",
    "    def get_model(self, model_name) -> Model:\n",
    "        return OpenAIChatCompletionsModel(model=\"gpt-4o\", openai_client=client)\n",
    "\n",
    "GITHUB_MODEL_PROVIDER = GitHubModelProvider()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7987428",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"Assistant\", \n",
    "    instructions=\"Answer the user's questions.\",\n",
    "    tools=[get_weather],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fa43712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This example uses a custom provider for some calls to Runner.run(), and direct calls to OpenAI for\\nothers. Steps:\\n1. Create a custom OpenAI client.\\n2. Create a ModelProvider that uses the custom client.\\n3. Use the ModelProvider in calls to Runner.run(), only when we want to use the custom LLM provider.\\n\\nNote that in this example, we disable tracing under the assumption that you don't have an API key\\nfrom platform.openai.com. If you do have one, you can either set the `OPENAI_API_KEY` env var\\nor call set_tracing_export_api_key() to set a tracing specific key.\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"This example uses a custom provider for some calls to Runner.run(), and direct calls to OpenAI for\n",
    "others. Steps:\n",
    "1. Create a custom OpenAI client.\n",
    "2. Create a ModelProvider that uses the custom client.\n",
    "3. Use the ModelProvider in calls to Runner.run(), only when we want to use the custom LLM provider.\n",
    "\n",
    "Note that in this example, we disable tracing under the assumption that you don't have an API key\n",
    "from platform.openai.com. If you do have one, you can either set the `OPENAI_API_KEY` env var\n",
    "or call set_tracing_export_api_key() to set a tracing specific key.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3586aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] getting weather for New York\n",
      "The current weather in New York is 44Â°C with windy conditions.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/openai/openai-agents-python/blob/main/examples/model_providers/custom_example_provider.py\n",
    "result = await Runner.run(\n",
    "    agent, \n",
    "    \"What is the weather in New York?\", \n",
    "    run_config=RunConfig(model_provider=GITHUB_MODEL_PROVIDER),\n",
    ")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cf42f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent(name='Assistant', instructions=\"Answer the user's questions.\", handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[FunctionTool(name='get_weather', description='', params_json_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weather_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x000001F632685080>, strict_json_schema=True)], mcp_servers=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.last_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb529b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
