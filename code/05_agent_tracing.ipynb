{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "863b46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mlflow.org/docs/latest/tracing/integrations/openai-agent\n",
    "# https://openai.github.io/openai-agents-python/tracing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb277cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import (\n",
    "\n",
    "    Agent,\n",
    "    Runner,\n",
    "    OpenAIChatCompletionsModel,\n",
    "    ModelProvider,\n",
    "    Model,\n",
    "    RunConfig,\n",
    "    set_default_openai_client,\n",
    "    set_default_openai_api,\n",
    "    set_tracing_disabled,\n",
    "    set_tracing_export_api_key,\n",
    "    trace,\n",
    "\n",
    "\n",
    "    function_tool,\n",
    ")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9cfd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    ")\n",
    "\n",
    "set_default_openai_client(client)\n",
    "set_default_openai_api(\n",
    "    ['chat_completions']\n",
    ")\n",
    "set_tracing_export_api_key(os.environ[\"OPENAI_TRACING_KEY\"])\n",
    "set_tracing_disabled(False)\n",
    "\n",
    "# tr = trace(workflow_name=\"msdiagentic_hello_tracking\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d46457d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f12b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# TODO: add a strongly typed return value for the get_weather function\n",
    "# exmple: def get_weather(city: str) -> WeatherInfo:\n",
    "# https://github.com/openai/openai-agents-python/blob/main/examples/basic/tools.py\n",
    "\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    city: str\n",
    "    temperature: str\n",
    "    conditions: str\n",
    "\n",
    "\n",
    "class CurrentTime(BaseModel):\n",
    "    location: str = Field(..., description=\"The name of the location\")\n",
    "    current_time: str = Field(..., description=\"The current time in the location\")\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str):\n",
    "    print(f\"[debug] getting weather for {city}\")\n",
    "    temperature = f\"{random.randint(-10, 50)}C\"\n",
    "    conditions = random.choice([\"Sunny\", \"Windy\", \"Rainy\", \"Cloudy\"])\n",
    "    return Weather(city=city, temperature=temperature, conditions=conditions)\n",
    "\n",
    "@function_tool\n",
    "def get_current_time(location):\n",
    "    from datetime import datetime\n",
    "    \"\"\"Get the current time for a given location\"\"\"\n",
    "    print(f\"[debug] get_current_time called with location: {location}\")\n",
    "    location_lower = location.lower()\n",
    "\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%I:%M %p\")\n",
    "    return CurrentTime(\n",
    "        location=location,\n",
    "        current_time=current_time,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2372a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GitHubModelProvider(ModelProvider):\n",
    "    def get_model(self, model_name) -> Model:\n",
    "        return OpenAIChatCompletionsModel(model=\"gpt-4o\", openai_client=client)\n",
    "\n",
    "GITHUB_MODEL_PROVIDER = GitHubModelProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7987428",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"Answer the user's questions.\",\n",
    "    tools=[get_weather, get_current_time],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fa43712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This example uses a custom provider for some calls to Runner.run(), and direct calls to OpenAI for\\nothers. Steps:\\n1. Create a custom OpenAI client.\\n2. Create a ModelProvider that uses the custom client.\\n3. Use the ModelProvider in calls to Runner.run(), only when we want to use the custom LLM provider.\\n\\nNote that in this example, we disable tracing under the assumption that you don't have an API key\\nfrom platform.openai.com. If you do have one, you can either set the `OPENAI_API_KEY` env var\\nor call set_tracing_export_api_key() to set a tracing specific key.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"This example uses a custom provider for some calls to Runner.run(), and direct calls to OpenAI for\n",
    "others. Steps:\n",
    "1. Create a custom OpenAI client.\n",
    "2. Create a ModelProvider that uses the custom client.\n",
    "3. Use the ModelProvider in calls to Runner.run(), only when we want to use the custom LLM provider.\n",
    "\n",
    "Note that in this example, we disable tracing under the assumption that you don't have an API key\n",
    "from platform.openai.com. If you do have one, you can either set the `OPENAI_API_KEY` env var\n",
    "or call set_tracing_export_api_key() to set a tracing specific key.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3586aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[error] Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 37834 seconds before retrying.', 'details': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 37834 seconds before retrying.'}}\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/openai/openai-agents-python/blob/main/examples/model_providers/custom_example_provider.py\n",
    "\n",
    "\n",
    "try:\n",
    "    with trace(workflow_name=\"msdiagentic_hello_tracking\"):\n",
    "        result = await Runner.run(\n",
    "            agent,\n",
    "            \"What is the weather in New York? And what is the time?\",\n",
    "            run_config=RunConfig(model_provider=GITHUB_MODEL_PROVIDER),\n",
    "\n",
    "        )\n",
    "        print(result.final_output)\n",
    "except Exception as e:\n",
    "    print(f\"[error] {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cce73a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace workflow name: Dummy_20250330_092715\n",
      "Trace ID: trace_184605ba5e64451f9b945b5aaa3dca82\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "tr = trace(\n",
    "    workflow_name=f\"Dummy_{timestamp}\",\n",
    "    group_id=\"Dummy Group\",\n",
    "    metadata={\n",
    "        \"key1\": \"value1\",\n",
    "        \"key2\": \"value2\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# print trace workflow name\n",
    "print(f\"Trace workflow name: {tr.name}\")\n",
    "tr.start()\n",
    "\n",
    "trace_id = tr.trace_id\n",
    "print(f\"Trace ID: {trace_id}\")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    model_provider=GITHUB_MODEL_PROVIDER,\n",
    "    trace_id=trace_id,  # Pass the trace ID to the run config\n",
    "    trace_metadata={\"AgentName\": \"WeatherAgent\"},\n",
    "    workflow_name=tr.name,  # Pass the workflow name to the run config\n",
    "    group_id=tr.group_id,  # Pass the group ID to the run config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812737e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[error] Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 37810 seconds before retrying.', 'details': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 37810 seconds before retrying.'}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = await Runner.run(\n",
    "            agent,\n",
    "            \"What is the weather in New York? And time.\",\n",
    "            run_config=run_config,\n",
    "        )\n",
    "\n",
    "    print(result.final_output)\n",
    "except Exception as e:\n",
    "    print(f\"[error] {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[error] Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 37789 seconds before retrying.', 'details': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 37789 seconds before retrying.'}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = await Runner.run(\n",
    "            agent,\n",
    "            \"What is the time in Sydney\",\n",
    "            run_config=run_config,\n",
    "        )\n",
    "\n",
    "    print(result.final_output)\n",
    "except Exception as e:\n",
    "    print(f\"[error] {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1368918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[error] Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 37770 seconds before retrying.', 'details': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 37770 seconds before retrying.'}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = await Runner.run(\n",
    "            agent,\n",
    "            \"Tell me a joke!\",\n",
    "            run_config=run_config,\n",
    "        )\n",
    "\n",
    "    print(result.final_output)\n",
    "except Exception as e:\n",
    "    print(f\"[error] {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebcf5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4339e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing URL: https://platform.openai.com/traces/trace?trace_id=trace_184605ba5e64451f9b945b5aaa3dca82\n"
     ]
    }
   ],
   "source": [
    "tracing_url = f\"https://platform.openai.com/traces/trace?trace_id={trace_id}\"\n",
    "\n",
    "print(f\"Tracing URL: {tracing_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9068b",
   "metadata": {},
   "source": [
    "View Traces [here](https://platform.openai.com/traces?group_id=Dummy+Group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2531f",
   "metadata": {},
   "source": [
    "# Add Viz\n",
    "\n",
    "requires GraphViz extension to view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31a6857f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH\n"
     ]
    }
   ],
   "source": [
    "from agents.extensions.visualization import draw_graph\n",
    "\n",
    "try:\n",
    "    draw_graph(agent, filename=\"viz/05_agent_tracing.gv\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4def31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
